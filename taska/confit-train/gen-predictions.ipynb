{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "# Had 44.9 ROUGE-1\n",
    "model_path = '/gpfs/slayman/pi/gerstein/xt86/jeffreytan/andrew/taska/confit-train/output-mediqa/4/checkpoint-7776'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_path).to('cuda')\n",
    "\n",
    "gold_summaries = []\n",
    "predictions = []\n",
    "\n",
    "with open('New-TaskA-ValidationData.jsonl') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line)\n",
    "        dialog = '\\n'.join(json_obj['dialogue'])\n",
    "        gold_summary = ' '.join(json_obj['summary'])\n",
    "        gold_summaries.append(gold_summary)\n",
    "\n",
    "        inputs_dict = tokenizer(\n",
    "            dialog, max_length=1024, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = inputs_dict.input_ids.to(\"cuda\")\n",
    "        attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n",
    "\n",
    "        output_ids = model.generate(input_ids, attention_mask=attention_mask, max_length=128, num_beams=6)\n",
    "\n",
    "        prediction = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "        print('Dialog: ' + dialog)\n",
    "        print('Prediction: ' + prediction)\n",
    "        print('----')\n",
    "        predictions.append(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "predictions = [l[0] for l in predictions]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "23733"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('predictions-1863.txt', 'w').write('\\n'.join(predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
